<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" MadCap:searchable="False" MadCap:lastBlockDepth="4" MadCap:lastHeight="3250" MadCap:lastWidth="1352">
    <head>
    </head>
    <body>
        <p style="text-align: center;"><span style="font-size: 18pt; color: #dae691;"><span style="color: #b5cb2b;font-weight: bold;">Cloudian S3 Kubernetes Provisioner Quick Start</span></span>
        </p>
        <p>&#160;</p>
        <p>&#160;</p>
        <p>&#160;</p>
        <p>&#160;</p>
        <p>DEPLOY.MD ORIGINAL</p>
        <p>This guide shows you how to deploy the Cloudian S3 Provisioner for Kubernetes to allow you to use Object Bucket Claim, so your deployments have easy access to HyperStore buckets.</p>
        <p>It assumes a good working knowledge of Kubernetes and that you have `kubectl` on your path with permissions to run it.</p>
        <h2 id="h2_quick_start">Create the Object Bucket and Object Bucket Claim Custom Resource Definitions</h2>
        <p>Firstly, we need to create the generic Object Bucket and Object Bucket provisioner resources.  This only needs to be done once.</p>
        <p>Simply run</p><pre>kubectl apply -f https://raw.githubusercontent.com/kube-object-storage/lib-bucket-provisioner/master/deploy/crds/objectbucket_v1alpha1_objectbucket_crd.yaml</pre><pre>kubectl apply -f https://raw.githubusercontent.com/kube-object-storage/lib-bucket-provisioner/master/deploy/crds/objectbucket_v1alpha1_objectbucketclaim_crd.yaml</pre>
        <h2 id="h2_quick_start">Deploy the S3 Provisioner</h2>
        <p>Next we need to deploy the Cloudian provisioner.  This only needs to be done once per Kubernetes cluster.</p>
        <p>Simply run</p><pre>kubectl apply -f https://raw.githubusercontent.com/cloudian/cloudian-s3-operator/hyperstore/examples/cloudian-s3-provisioner.yaml</pre>
        <p>This deploys a provisioner in the `s3-provisioner` namespace.</p>
        <h2 id="h2_quick_start">Create Owner Secret</h2>
        <p>We need to give the Kubernetes cluster the ability to connect to HyperStore.  You need credentials from a user who has sufficient rights to create/delete/get buckets and IAM users.  Again, only one of these is needed per Kubernetes cluster.</p>
        <p>Create 'owner-secret.yaml':</p><pre xml:space="preserve">apiVersion: v1
kind: Secret
metadata:
  name: s3-bucket-owner
  namespace: cloudian-s3-operator
type: Opaque
data:
  AWS_ACCESS_KEY_ID: base64_encoded_key
  AWS_SECRET_ACCESS_KEY: base64_encoded_secret</pre>
        <p>Ensure that your base64 encoded secret does not include the newline, using for example</p><pre>echo -n &lt;raw key&gt; | base64</pre>
        <p>to create it.</p>
        <p>Apply it with:</p><pre>kubectl apply -f owner-secret.yaml</pre>
        <p>As an alternative to using a YAML file for the owner secret, create these from the command line</p><pre>kubectl create secret -n s3-provisioner generic s3-bucket-owner --from-literal=AWS_ACCESS_KEY_ID=&lt;access key&gt; --from-literal=AWS_SECRET_ACCESS_KEY=&lt;secret key&gt;</pre>
        <h2 id="h2_quick_start">Create Storage Class</h2>
        <p>You may need multiple storage classes.  You can either create "greenfield" (each new deployment gets access to a newly created, empty bucket) or "brownfield" (each deployment gets access to a pre-created bucket) type classes.</p>
        <p>Create `storage-class.yaml`:</p><pre xml:space="preserve">kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: &lt;tag for this class, e.g. hyperstore-buckets&gt;
provisioner: cloudian-s3.io/bucket
parameters:
  region: &lt;region e.g. reg-1&gt;
  secretName: s3-bucket-owner
  secretNamespace: cloudian-s3-operator
  bucketName: &lt;existing bucket name, e.g. photos, or delete&gt; - brownfield only
  s3Endpoint: &lt;API server URL, e.g. http://s3-reg-1.landemo1.cloudian.eu&gt;
  iamEndpoint: &lt;IAM API server URL, e.g. http://iam.landemo1.cloudian.eu:16080&gt;
  storagePolicyId: &lt;Storage Policy ID - or omit line to use default storage policy&gt; - greenfield only
  createBucketUser: &lt;optional - control whether the provisioner creates IAM users. Either "yes" or "no", default is "yes"&gt;
  bucketClaimUserSecretName: &lt;optional - a separate secret holding credentials to provide to object bucket claim if user creation is disabled&gt;
  bucketClaimUserSecretNamespace: &lt;namespace for bucketClaimUserSecretName, required if bucketClaimUserSecretName is set&gt;
  iamPolicy: &lt;IAM policy document (JSON string) for users of this bucket - omit to use default IAM policy (read+write bucket). Only applies if IAM user creation enabled&gt;
reclaimPolicy: Delete</pre>
        <p>This file needs some customization, depending on your setup.</p>
        <ol>
            <li>Change metdata.name to a unique tag for this storage class.</li>
            <li>Change region, s3Endpoint and iamEndpoint to match your HyperStore setup</li>
            <li>For greenfield: delete bucketName and optionally set the storage policy to use for new buckets. Omit the storagePolicyId line to use the default policy. To find the policy ID, navigate to the Cluster-&gt;Storage Policies page on the CMC, select View/Edit for the policy, and copy the ID field (above the Policy Name field)</li>
            <li>For brownfield: specify an already created bucket name and delete reclaimPolicy and storagePolicyId</li>
            <li>Optionally disable IAM user creation for bucket access by setting `createBucketUser` to `"no"`. A separate secret can be used to hold a shared credentials granted to all object bucket claims for this storage class by setting `bucketClaimUserSecretName` and `bucketClaimUserSecretNamespace`. If this secret is unset, the credentials from the `secretNamespace/secretName` are provided to object bucket claims.</li>
            <li>Optionally specify an IAM policy document to override default read+write access to the bucket. You do not need to specify `Resource` fields - they will be set to only allow access to the provisioned bucket. Only applicable if IAM user creation is enabled. For example, to grant read-only access to the bucket:</li>
        </ol>
        <div class="Indent"><pre xml:space="preserve">iamPolicy: |
  {
    "Version": "2012-10-17",
    "Statement": [{
      "Sid": "AllowAll",
      "Effect": "Allow",
      "Action": ["s3:HeadObject", "s3:ListBucket", "s3:GetObject"]
  }]
}</pre>
        </div>
        <p>Apply this with:</p><pre>kubectl apply -f storage-class.yaml</pre>
        <h2 id="h2_quick_start">Checking Your Setup</h2>
        <p>Create a `test.yaml` file that creates bucket claim and pod that binds environment variables to the config map and secret the provisioner generates:</p><pre xml:space="preserve">apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim
metadata:
name: test-setup-check
spec:
generateBucketName: test-setup-check
storageClassName: &lt;object storage class you want to check, e.g. hyperstore-buckets&gt;
---
apiVersion: v1
kind: Pod
metadata:
name: test-setup-check
spec:
containers:
- name: test-setup-check
image: k8s.gcr.io/busybox
command: [ "/bin/sh", "-c", "env" ]
envFrom:
- configMapRef:
name: test-setup-check
- secretRef:
name: test-setup-check
restartPolicy: Never</pre>
        <p>Deploy the `test.yaml`, wait until the test pod exists, then look at the logs and check the environment variables. Use the HyperStore CMC to verify the bucket has been created and an IAM user created that only has access rights to the bucket.</p>
        <p>```</p>
        <p>kubectl apply -f test.yaml</p>
        <p>kubectl get pods -w test-setup-check</p>
        <p># Wait until pod is status completed, then hit ctrl-c</p>
        <p>kubectl logs test-setup-check | grep BUCKET_</p>
        <p>```</p>
        <p>You should see the following environment variables set</p>
        <p>```bash</p>
        <p>BUCKET_HOST=s3-reg-1.landemo1.cloudian.eu</p>
        <p>BUCKET_PORT=80</p>
        <p>BUCKET_NAME=check-setup-ccf09b7c-ce06-431c-bc7d-9ddd5af8d192</p>
        <p>BUCKET_SUBREGION=</p>
        <p>BUCKET_REGION=reg-1</p>
        <p>```</p>
        <p>and the bucket and similarly looking IAM user created.  You'll also see the AWS credentials in the log too.  These details can be used to access HyperStore for that bucket only.</p>
        <p>Delete this deployment, and use the CMC to check the test bucket and IAM user have been deleted:</p>
        <p>```</p>
        <p>kubectl delete -f test.yaml</p>
        <p>```</p>
        <p>If you look in CMC, you'll see the bucket and IAM user are gone.</p>
    </body>
</html>