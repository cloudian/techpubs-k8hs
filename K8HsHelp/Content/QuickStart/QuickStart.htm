<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" MadCap:searchable="False" MadCap:lastBlockDepth="6" MadCap:lastHeight="7674" MadCap:lastWidth="1352">
    <head>
    </head>
    <body>
        <p style="text-align: center;"><span style="font-size: 18pt; color: #dae691;"><span style="color: #b5cb2b;font-weight: bold;">Cloudian Kubernetes S3 Operator Quick Start</span></span>
        </p>
        <p>The Cloudian Kubernetes S3 Operator makes it easy for Kubernetes-orchestrated applications to use Cloudian HyperStore as their S3-driven object storage target. With the Cloudian S3 Operator, you can use familiar Kubernetes resources and tooling to make HyperStore object storage buckets dynamically available to containerized application that have S3 client capabilities. Such applications can then read and write to those object storage buckets using standard S3 API calls.</p>
        <p>This document describes how to deploy the Cloudian S3 Operator, create the relevant Kubernetes resources, and have Kubernetes-orchestrated applications use Cloudian S3 object storage. The document assumes a working knowledge of Kubernetes and its tooling.</p>
        <ul>
            <li>
                <MadCap:xref href="#Requirem">Requirements</MadCap:xref>
            </li>
            <li>
                <MadCap:xref href="#Preparin">Preparing Your HyperStore System for Kubernetes Access</MadCap:xref>
            </li>
            <li>
                <MadCap:xref href="#Deployin">Deploying the Cloudian S3 Provisioner in Your Kubernetes Cluster</MadCap:xref>
            </li>
            <li>
                <MadCap:xref href="#Setting">Creating a Kubernetes Secret and a Storage Class for Cloudian S3 Object Storage</MadCap:xref>
            </li>
            <li>
                <MadCap:xref href="#Having">Having an Application Pod Use Cloudian S3 Object Storage</MadCap:xref>
            </li>
        </ul>
        <h2 id="h2_quick_start"><a name="Requirem"></a>Requirements</h2>
        <ul>
            <li>HyperStore version 7.2 or newer</li>
            <li>Kubernetes version TBD</li>
            <li>A&#160;containerized application with S3 client capabilities, that you will run in your Kubernetes cluster</li>
        </ul>
        <h2 id="h2_quick_start"><a name="Preparin"></a>Preparing Your HyperStore System for Kubernetes Access</h2>
        <p>If you have not already done so, complete the following basic setup tasks in your HyperStore system before deploying the Cloudian S3 Operator in your Kubernetes cluster:</p>
        <ul>
            <li>Create <b>at least one storage policy</b>.</li>
            <li>Create <b>a HyperStore user account</b>, to be used by the Cloudian S3 Operator. This needs to be user root account with permissions to create and access buckets and to create IAM&#160;users and policies. HyperStore user root accounts have such permissions by default.<ul><li><b>Optionally, create a bucket</b> under this account if you want to support  "brownfield" object storage for your Kubernetes cluster (where multiple object bucket claims share the same pre-existing bucket). For "greenfield" object storage (where each object bucket claim gets its own newly created bucket), for each claim the Cloudian S3 Operator will dynamically create a new bucket under this user account.</li><li><b>Optionally, create an IAM&#160;user</b> under this account if you will want multiple object bucket claims to access buckets as the same, shared pre-existing IAM&#160;user.  Alternatively, for each object bucket claim the Cloudian S3 Operator can dynamically create a new IAM user under this user account and then the IAM&#160;user when the claim ends. If you do create an IAM user for claims to share,  be sure to give the IAM&#160;user permissions to access all buckets created under the root account.</li></ul></li>
        </ul>
        <p>For detail about performing these HyperStore tasks see your HyperStore product documentation.</p>
        <p>When setting up the Cloudian S3 Operator in your Kubernetes environment you will need the following <b>information from your HyperStore system</b>:</p>
        <ul>
            <li>The name of the HyperStore service region in which you want the Cloudian S3 Operator to create buckets (or to use a pre-existing bucket).</li>
            <li>The S3 Service endpoint for that HyperStore service region.</li>
            <li>The IAM&#160;Service endpoint for the HyperStore system.</li>
            <li>The S3 credentials (access key ID and secret access key) for the HyperStore user account that the Cloudian S3 Operator will use to provision buckets.</li>
            <li>If you created an IAM&#160;user for object bucket claims to share, the S3 credentials for that IAM&#160;user.</li>
            <li>If you created a bucket for object bucket claims to share, the name of that bucket.</li>
            <li>If you want Cloudian S3 Operator generated buckets to use a HyperStore storage policy other than the default storage policy in your HyperStore system, you will need the storage policy ID (not the policy name but rather the system-generated policy ID). You can see a storage policy's ID in the CMC:&#160;<b>Cluster -&gt; Storage Policies -&gt; View/Edit</b>.</li>
        </ul>
        <h2 id="h2_quick_start"><a name="Deployin"></a>Deploying the Cloudian S3 Operator in Your Kubernetes Cluster</h2>
        <p>Deploying the Cloudian Kubernetes S3 Operator in your Kubernetes cluster will enable you to use a combination of standard Kubernetes resources (Secret and StorageClass) and custom Kubernetes resources (ObjectBucket and ObjectBucketClaim) to automate the provisioning of Cloudian HyperStore object storage for your containerized applications. The ObjectBucket/ObjectBucketClaim provisioning model for Kubernetes is analogous to how the standard PersistentVolume and PersistentVolumeClaim (PV/PVC) resources work for block and file storage, except with custom resources tailored to the requirements of object storage.</p>
        <p>In the steps below it is assumed that you are on a machine with internet access. Also, here and throughout the remainder of the instructions in this document it is assumed that the Kubernetes command line tool <em>kubectl</em> is in your path and that you have permissions to run it.</p>
        <p>First, run these commands to create the ObjectBucket and ObjectBucketClaim custom resource definitions in your Kubernetes cluster:</p><pre># kubectl apply -f https://raw.githubusercontent.com/kube-object-storage/lib-bucket-provisioner/master/deploy/crds/objectbucket_v1alpha1_objectbucket_crd.yaml</pre><pre># kubectl apply -f https://raw.githubusercontent.com/kube-object-storage/lib-bucket-provisioner/master/deploy/crds/objectbucket_v1alpha1_objectbucketclaim_crd.yaml</pre>
        <p>These custom resource definitions (CRDs) are not specific to Cloudian HyperStore. They are general purpose CRDs for provisioning object storage for Kubernetes clusters. The Cloudian S3 Operator utilizes these CRDs.</p>
        <p>Next, run this command to deploy the Cloudian S3 Operator in your Kubernetes cluster:</p><pre># kubectl apply -f https://raw.githubusercontent.com/cloudian/cloudian-s3-operator/hyperstore/examples/cloudian-s3-provisioner.yaml</pre>
        <p>This deploys a provisioner in the <em>cloudian-s3-operator</em> namespace.</p>
        <h2 id="h2_quick_start"><a name="Setting"></a>Creating a Kubernetes Secret and a Storage Class for Cloudian S3 Object Storage</h2>
        <h3 id="h3_quick_start"><a name="Create"></a>Create the Bucket Owner Secret</h3>
        <p>Next you will create a Kubernetes Secret that encapsulates the S3 security credentials of the HyperStore user account that  the Cloudian S3 Operator will use when it provisions buckets (the account noted in the <MadCap:xref href="#Requirem">Requirements</MadCap:xref> section of this document). When creating the Secret you will need the S3 access key ID and the secret access key to be base64 encoded, without any newline. You can create the base64 encodings by running the following commands:</p><pre xml:space="preserve"># echo -n &lt;raw access key id&gt; | base64</pre><pre xml:space="preserve"># echo -n &lt;raw secret access key&gt; | base64</pre>
        <p>With the base64 encoded S3 credentials at hand, create a file named <em>owner-secret.yaml</em> with the following content:</p><pre xml:space="preserve">apiVersion: v1
kind: Secret
metadata:
  name: s3-bucket-owner
  namespace: cloudian-s3-operator
type: Opaque
data:
  AWS_ACCESS_KEY_ID: &lt;base64_encoded_access_key_id&gt;
  AWS_SECRET_ACCESS_KEY: &lt;base64_encoded_secret_access_key&gt;</pre>
        <p>Then create the resource in your cluster with this command:</p><pre xml:space="preserve"># kubectl create -f owner-secret.yaml</pre>
        <p><b>Optionally</b> you can create a second Secret, in the same manner as described above, that encapsulates the S3 credentials of an IAM&#160;user that you have created in HyperStore under the bucket owner account. This is applicable only if you intend to have multiple object bucket claims use the same pre-existing IAM&#160;user when accessing HyperStore buckets -- rather than the Cloudian S3 Operator default behavior which is to dynamically create a new IAM&#160;user (under the bucket owner account) for each object bucket claim, and then automatically delete that IAM&#160;user when the claim ends.</p>
        <h3 id="h3_quick_start">Create One or More Storage Classes</h3>
        <p>Next, create at least one Storage Class for Cloudian object storage. A Storage Class is a standard Kubernetes resource that you have likely used before for other types of storage, but in this case the specified provisioner will be the Cloudian S3 Operator and the parameters will be specific to the needs of object storage provisioning. If you wish you can create multiple Storage Classes for Cloudian object storage -- for example, one Storage Class for "greenfield" storage (each application pod deployment gets access to a newly created, empty bucket in Cloudian HyperStore) and one Storage Class for "brownfield" storage (each application pod deployment gets access to an existing bucket in Cloudian HyperStore). Greenfield and brownfield Storage Class configurations are both described below.</p>
        <p><b>To create a Storage Class for greenfield Cloudian object storage</b>, create a file named <em>storageclass-greenfield.yaml</em> with the following content:</p><pre xml:space="preserve">kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: &lt;storage class name&gt;   <b>[1]</b>
provisioner: cloudian-s3.io/bucket
parameters:
  region: &lt;hyperstore service region&gt;   <b>[2]</b>
  secretName: s3-bucket-owner   <b>[3]</b>
  secretNamespace: cloudian-s3-operator
  s3Endpoint: &lt;S3 service endpoint&gt;   <b>[4]</b>
  iamEndpoint: &lt;IAM service endpoint&gt;   <b>[5]</b>
  storagePolicyId: &lt;optional storage policy ID&gt;   <b>[6]</b>
  createBucketUser: &lt;optional override of creating an IAM&#160;user per bucket claim&gt;   <b>[7]</b>
  bucketClaimUserSecretName: &lt;optional dedicated Secret for bucket access&gt;   <b>[7]</b>
  bucketClaimUserSecretNamespace: &lt;only if bucketClaimUserSecretName is set&gt;   <b>[7]</b>
  iamPolicy: &lt;optional IAM policy document&gt;   <b>[8]</b>
reclaimPolicy: Delete   <b>[9]</b></pre>
        <ol>
            <li>Name to give to this Storage Class, for example <em>hyperstore-greenfield</em>. This will be referenced in the object bucket claim.</li>
            <li>Name of the HyperStore service region in which you want greenfield object storage buckets to be created.</li>
            <li>This references the name of the bucket owner Secret that you created previously.</li>
            <li>The S3 Service endpoint of the HyperStore service region named by the region parameter. Specify the endpoint in the form of a URL -- for example <em>http://s3-region1.mycloudianhyperstore.com</em>. If the port number is not 80, include the port number at the end of the URL (<em>:&lt;port#&gt;</em>). Important:&#160;Be sure your Kubernetes cluster can resolve this endpoint.</li>
            <li>The IAM Service endpoint of your HyperStore system. Specify the endpoint in the form of a URL -- for example <em>http://iam.mycloudianhyperstore.com:16080</em>. If the port number is not 80, include the port number at the end of the URL (<em>:&lt;port#&gt;</em>). Important:&#160;Be sure your Kubernetes cluster can resolve this endpoint.</li>
            <li>If you want newly created buckets to use a HyperStore storage policy other than the default storage policy, specify the storage policy ID&#160;here (for background information see the <MadCap:xref href="#Requirem">Requirements</MadCap:xref> section). If you want newly created buckets to use the default HyperStore storage policy, omit the <em>storagePolicyId</em> parameter.</li>
            <li>By default the Cloudian S3 Operator creates a new IAM&#160;user (with its own unique S3 credentials) for each object bucket claim. To use this default behavior, omit the <em>createBucketUser</em> parameter,  <em>bucketClaimUserSecretName</em> parameter, and <em>bucketClaimUserSecretNamespace</em> parameter. If instead you want all object bucket claims to access HyperStore buckets as the same shared user, using the same shared S3 credentials, set the <em>createBucketUser</em> parameter to <em>"no"</em>(including the quote marks). If you want that one shared user for bucket access to be the same account root user used by the Cloudian S3 Operator to provision buckets, omit the <em>bucketClaimUserSecretName</em> and <em>bucketClaimUserSecretNamespace</em> parameters. If you want that one shared user for bucket access to be a pre-existing IAM&#160;user that you have created under the bucket owner root account, and you have created a Secret that encapsulates that IAM user's S3 credentials (as described in in <MadCap:xref href="#Create">Create the Bucket Owner Secret</MadCap:xref>), use the <em>bucketClaimUserSecretName</em> and <em>bucketClaimUserSecretNamespace</em> parameters to reference that Secret.</li>
            <li>Include the <em>iamPolicy</em> parameter only if you are having the Cloudian S3 Operation automatically create a new IAM&#160;user for each object bucket claim (i.e. in the Storage Class the <em>createBucketUser</em> parameter is omitted or explicitly set to "yes") and if you want those dynamically created IAM&#160;users to have something less than full read and write permissions on the bucket (which is the default permission that the Cloudian S3 Operator grants to IAM&#160;users that it creates). If you do include the <em>iamPolicy</em> parameter, set it as a JSON-formatted IAM&#160;policy document. You do not need to include a "Resource" field in the document, since the policy will automatically apply only to the provisioned bucket. For example, to grant read-only access to the bucket:</li>
        </ol>
        <div class="Indent"><pre xml:space="preserve">iamPolicy: |
  {
    "Version": "2012-10-17",
    "Statement": [{
      "Sid": "ReadOnly",
      "Effect": "Allow",
      "Action": ["s3:HeadObject", "s3:ListBucket", "s3:GetObject"]
  }]
}</pre>
        </div>
        <ol MadCap:continue="true">
            <li>With <em>reclaimPolicy</em> set to <em>Delete</em>, the bucket will be automatically deleted when the object bucket claim is deleted. Alternatively you could set this to <em>Retain</em> in which the bucket will not be deleted when the object bucket claim is deleted.</li>
        </ol>
        <p>Then create the resource in your cluster with this command:</p><pre xml:space="preserve"># kubectl create -f storageclass-greenfield.yaml</pre>
        <p><b>To create a Storage Class for brownfield Cloudian object storage</b>, create a file named <em>storageclass-brownfield.yaml</em> with the following content:</p><pre xml:space="preserve">kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: &lt;storage class name&gt;   <b>[1]</b>
provisioner: cloudian-s3.io/bucket
parameters:
  region: &lt;hyperstore service region&gt;   <b>[2]</b>
  secretName: s3-bucket-owner   <b>[3]</b>
  secretNamespace: cloudian-s3-operator
  bucketName: &lt;existing bucket in HyperStore&gt;   <b>[4]</b>
  s3Endpoint: &lt;S3 service endpoint&gt;   <b>[5]</b>
  iamEndpoint: &lt;IAM service endpoint&gt;   <b>[5]</b>
  createBucketUser: &lt;optional override of creating an IAM&#160;user per pod deployment&gt;   <b>[6]</b>
  bucketClaimUserSecretName: &lt;optional dedicated Secret for bucket access&gt;   <b>[6]</b>
  bucketClaimUserSecretNamespace: &lt;only if bucketClaimUserSecretName is set&gt;   <b>[6]</b>
  iamPolicy: &lt;optional IAM policy document&gt;   <b>[6]</b>
</pre>
        <ol>
            <li>Name to give to this Storage Class, for example <em>hyperstore-brownfield</em>. This will be referenced in the object bucket claim.</li>
            <li>The HyperStore service region in which the bucket named by the <em>bucketName</em> parameter is located.</li>
            <li>This references the name of the bucket owner Secret that you created previously.</li>
            <li>This is the name of an existing bucket in HyperStore, which will be used for all bucket claims associated with this Storage Class. This must be a bucket that is owned by the HyperStore account root user whose S3 credentials are encapsulated in the bucket owner Secret.</li>
            <li>For information about formatting the S3 Service endpoint and IAM&#160;Service endpoint, see the preceding description of a greenfield Cloudian object storage class. </li>
            <li>For information about the <em>createBucketUser</em>, <em>bucketClaimUserSecretName</em>, <em>bucketClaimUserSecretNamespace</em>, and <em>iamPolicy</em> parameters, see the preceding description of a greenfield Cloudian object storage class. </li>
        </ol>
        <p>Then create the resource in your cluster with this command:</p><pre xml:space="preserve"># kubectl create -f storageclass-brownfield.yaml</pre>
        <h2 id="h2_quick_start"><a name="Having"></a>Having an Application Pod Use Cloudian S3 Object Storage</h2>
        <p>Create an Object Bucket Claim (OBC):</p><pre xml:space="preserve">apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim
metadata:
  name: &lt;OBC name&gt;   <b>[1]</b>
  namespace: cloudian-s3-operator
spec:
  generateBucketName: &lt;greenfield bucket name prefix&gt;   <b>[2</b>]
  bucketName: &lt;greenfield bucket full name&gt;   <b>[2]</b>
  storageClassName: &lt;name of an object storage class that you created&gt;   <b>[3]</b></pre>
        <ol>
            <li>Name to give to this Object Bucket Claim.</li>
            <li>For a brownfield OBC, omit the <em>generateBucketName</em> and <em>bucketName</em> parameters (instead the bucket name will come from the brownfield storage class that you specify with the <em>storageClassName</em> parameter). For a greenfield OBC, you can use the <em>generateBucketName</em> to specify a bucket name prefix to which the Cloudian S3 Operator will append a random string to automatically create the full bucket name (a good approach for ensuring that the bucket has a unique name within HyperStore), and omit the <em>bucketName</em> parameter.  Or if you prefer you can omit the <em>generateBucketName</em> parameter and use the <em>bucketName</em> parameter to specify a full bucket name. If you mistakenly include both parameters and assign values to both, the <em>bucketName</em> parameter will override the <em>generateBucketName</em> parameter. </li>
            <li>Name of the storage class that this OBC will use, for example <em>hyperstore-greenfield</em> or <em>hyperstore-brownfield</em>.</li>
        </ol>
        <p>&#160;</p>
        <p>&#160;</p>
        <p style="font-weight: bold;">DEPLOY.MD ORIGINAL DEPLOY.MD ORIGINAL DEPLOY.MD ORIGINAL</p>
        <p style="font-weight: bold;">DEPLOY.MD ORIGINAL DEPLOY.MD ORIGINAL DEPLOY.MD ORIGINAL</p>
        <p style="font-weight: bold;">DEPLOY.MD ORIGINAL DEPLOY.MD ORIGINAL DEPLOY.MD ORIGINAL</p>
        <p style="font-weight: bold;">DEPLOY.MD ORIGINAL DEPLOY.MD ORIGINAL DEPLOY.MD ORIGINAL</p>
        <p>This guide shows you how to deploy the Cloudian S3 Provisioner for Kubernetes to allow you to use Object Bucket Claim, so your deployments have easy access to HyperStore buckets.</p>
        <p>It assumes a good working knowledge of Kubernetes and that you have <em>kubectl</em> on your path with permissions to run it.</p>
        <h2 id="h2_quick_start">Create the Object Bucket and Object Bucket Claim Custom Resource Definitions</h2>
        <p>Firstly, we need to create the generic Object Bucket and Object Bucket provisioner resources.  This only needs to be done once.</p>
        <p>Simply run</p><pre>kubectl apply -f https://raw.githubusercontent.com/kube-object-storage/lib-bucket-provisioner/master/deploy/crds/objectbucket_v1alpha1_objectbucket_crd.yaml</pre><pre>kubectl apply -f https://raw.githubusercontent.com/kube-object-storage/lib-bucket-provisioner/master/deploy/crds/objectbucket_v1alpha1_objectbucketclaim_crd.yaml</pre>
        <h2 id="h2_quick_start">Deploy the S3 Provisioner</h2>
        <p>Next we need to deploy the Cloudian provisioner.  This only needs to be done once per Kubernetes cluster.</p>
        <p>Simply run</p><pre>kubectl apply -f https://raw.githubusercontent.com/cloudian/cloudian-s3-operator/hyperstore/examples/cloudian-s3-provisioner.yaml</pre>
        <p>This deploys a provisioner in the <em>s3-provisioner</em> namespace.</p>
        <h2 id="h2_quick_start">Create Owner Secret</h2>
        <p>We need to give the Kubernetes cluster the ability to connect to HyperStore.  You need credentials from a user who has sufficient rights to create/delete/get buckets and IAM users.  Again, only one of these is needed per Kubernetes cluster.</p>
        <p>Create <em>owner-secret.yaml</em>:</p><pre xml:space="preserve">apiVersion: v1
kind: Secret
metadata:
  name: s3-bucket-owner
  namespace: cloudian-s3-operator
type: Opaque
data:
  AWS_ACCESS_KEY_ID: base64_encoded_key
  AWS_SECRET_ACCESS_KEY: base64_encoded_secret</pre>
        <p>Ensure that your base64 encoded secret does not include the newline, using for example</p><pre>echo -n &lt;raw key&gt; | base64</pre>
        <p>to create it.</p>
        <p>Apply it with:</p><pre>kubectl apply -f owner-secret.yaml</pre>
        <p>As an alternative to using a YAML file for the owner secret, create these from the command line</p><pre>kubectl create secret -n s3-provisioner generic s3-bucket-owner --from-literal=AWS_ACCESS_KEY_ID=&lt;access key&gt; --from-literal=AWS_SECRET_ACCESS_KEY=&lt;secret key&gt;</pre>
        <h2 id="h2_quick_start">Create Storage Class</h2>
        <p>You may need multiple storage classes.  You can either create "greenfield" (each new deployment gets access to a newly created, empty bucket) or "brownfield" (each deployment gets access to a pre-created bucket) type classes.</p>
        <p>Create <em>storage-class.yaml</em>:</p><pre xml:space="preserve">kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: &lt;tag for this class, e.g. hyperstore-buckets&gt;
provisioner: cloudian-s3.io/bucket
parameters:
  region: &lt;region e.g. reg-1&gt;
  secretName: s3-bucket-owner
  secretNamespace: cloudian-s3-operator
  bucketName: &lt;existing bucket name, e.g. photos, or delete&gt; - brownfield only
  s3Endpoint: &lt;API server URL, e.g. http://s3-reg-1.landemo1.cloudian.eu&gt;
  iamEndpoint: &lt;IAM API server URL, e.g. http://iam.landemo1.cloudian.eu:16080&gt;
  storagePolicyId: &lt;Storage Policy ID - or omit line to use default storage policy&gt; - greenfield only
  createBucketUser: &lt;optional - control whether the provisioner creates IAM users. Either "yes" or "no", default is "yes"&gt;
  bucketClaimUserSecretName: &lt;optional - a separate secret holding credentials to provide to object bucket claim if user creation is disabled&gt;
  bucketClaimUserSecretNamespace: &lt;namespace for bucketClaimUserSecretName, required if bucketClaimUserSecretName is set&gt;
  iamPolicy: &lt;IAM policy document (JSON string) for users of this bucket - omit to use default IAM policy (read+write bucket). Only applies if IAM user creation enabled&gt;
reclaimPolicy: Delete</pre>
        <p>This file needs some customization, depending on your setup.</p>
        <ol>
            <li>Change <em>metadata.name</em> to a unique tag for this storage class.</li>
            <li>Change <em>region</em>, <em>s3Endpoint</em> and <em>iamEndpoint</em> to match your HyperStore setup</li>
            <li>For greenfield: delete <em>bucketName</em> and optionally set the storage policy to use for new buckets. Omit the <em>storagePolicyId</em> line to use the default policy. To find the policy ID, navigate to the <b>Cluster-&gt;Storage Policies</b> page on the CMC, select <b>View/Edit</b> for the policy, and copy the ID field (above the Policy Name field)</li>
            <li>For brownfield: specify an already created bucket name and delete <em>reclaimPolicy </em>and <em>storagePolicyId</em></li>
            <li>Optionally disable IAM user creation for bucket access by setting <em>createBucketUser</em> to <em>"no"</em>. A separate secret can be used to hold a shared credentials granted to all object bucket claims for this storage class by setting <em>bucketClaimUserSecretName</em> and <em>bucketClaimUserSecretNamespace</em>. If this secret is unset, the credentials from the <em>secretNamespace/secretName</em> are provided to object bucket claims.</li>
            <li>Optionally specify an IAM policy document to override default read+write access to the bucket. You do not need to specify <em>Resource</em> fields - they will be set to only allow access to the provisioned bucket. Only applicable if IAM user creation is enabled. For example, to grant read-only access to the bucket:</li>
        </ol>
        <div class="Indent"><pre xml:space="preserve">iamPolicy: |
  {
    "Version": "2012-10-17",
    "Statement": [{
      "Sid": "AllowAll",
      "Effect": "Allow",
      "Action": ["s3:HeadObject", "s3:ListBucket", "s3:GetObject"]
  }]
}</pre>
        </div>
        <p>Apply this with:</p><pre>kubectl apply -f storage-class.yaml</pre>
        <h2 id="h2_quick_start">Checking Your Setup</h2>
        <p>Create a <em>test.yaml</em> file that creates bucket claim and pod that binds environment variables to the config map and secret the provisioner generates:</p><pre xml:space="preserve">apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim
metadata:
  name: test-setup-check
spec:
  generateBucketName: test-setup-check
  storageClassName: &lt;object storage class you want to check, e.g. hyperstore-buckets&gt;
---
apiVersion: v1
kind: Pod
metadata:
  name: test-setup-check
spec:
containers:
  - name: test-setup-check
  image: k8s.gcr.io/busybox
  command: [ "/bin/sh", "-c", "env" ]
  envFrom:
  - configMapRef:
    name: test-setup-check
  - secretRef:
    name: test-setup-check
  restartPolicy: Never</pre>
        <p>Deploy the <em>test.yaml</em>, wait until the test pod exists, then look at the logs and check the environment variables. Use the HyperStore CMC to verify the bucket has been created and an IAM user created that only has access rights to the bucket.</p><pre xml:space="preserve">kubectl apply -f test.yaml
kubectl get pods -w test-setup-check
# Wait until pod is status completed, then hit ctrl-c
kubectl logs test-setup-check | grep BUCKET_</pre>
        <p>You should see the following environment variables set</p><pre xml:space="preserve">BUCKET_HOST=s3-reg-1.landemo1.cloudian.eu
BUCKET_PORT=80
BUCKET_NAME=check-setup-ccf09b7c-ce06-431c-bc7d-9ddd5af8d192
BUCKET_SUBREGION=
BUCKET_REGION=reg-1</pre>
        <p>and the bucket and similarly looking IAM user created.  You'll also see the AWS credentials in the log too.  These details can be used to access HyperStore for that bucket only.</p>
        <p>Delete this deployment, and use the CMC to check the test bucket and IAM user have been deleted:</p><pre>kubectl delete -f test.yaml</pre>
        <p>If you look in CMC, you'll see the bucket and IAM user are gone.</p>
    </body>
</html>